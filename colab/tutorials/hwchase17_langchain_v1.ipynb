{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMq+BwJ1zf1yIQANRj9oyup",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dylanhogg/jupyter-experiments/blob/master/colab/tutorials/hwchase17_langchain_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# hwchase17/langchain example\n",
        "\n",
        "https://github.com/hwchase17/langchain  \n",
        "\n",
        "Building applications with LLMs through composability. \n",
        "\n",
        "Large language models (LLMs) are emerging as a transformative technology, enabling developers to build applications that they previously could not. However, using these LLMs in isolation is often insufficient for creating a truly powerful app - the real power comes when you can combine them with other sources of computation or knowledge.\n",
        "\n",
        "This library aims to assist in the development of those types of applications."
      ],
      "metadata": {
        "id": "l9gmIZixUQ_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install required packages"
      ],
      "metadata": {
        "id": "cTZb1bz4SboZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain -q\n",
        "%pip install openai -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThItY5V8Jgwc",
        "outputId": "149fb408-e43e-4ea9-ca05-4941fa857345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment set up"
      ],
      "metadata": {
        "id": "Xrm-TkbwU5_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass('Enter your OPENAI_API_KEY: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVUgQRiwWV10",
        "outputId": "0c07ebd2-5ca8-457b-84f8-92a55e20e266"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OPENAI_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "9LLazzscW-cO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "zGJ_R8HxSe57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "uTLZR8xRJgyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z8dvp84TUhvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chains: Combine LLMs and prompts in multi-step workflows\n",
        "\n",
        "https://python.langchain.com/en/latest/getting_started/getting_started.html#chains-combine-llms-and-prompts-in-multi-step-workflows"
      ],
      "metadata": {
        "id": "lPJyPsyVXIyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# llm = OpenAI(openai_api_key=\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "4cAEsVekUhxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.9)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\",\n",
        ")"
      ],
      "metadata": {
        "id": "ODEXcVhkUhzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "usewlVaeYFPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"colorful socks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BzQ_V6ABYL8Q",
        "outputId": "7e73e82a-b124-44f3-a6f9-71f61814ef50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nSockFiesta.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rjM34qWrYNFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLMMathChain\n",
        "\n",
        "https://python.langchain.com/en/latest/modules/chains/examples/llm_math.html"
      ],
      "metadata": {
        "id": "sFHWC1cDcAwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, LLMMathChain\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "llm_math = LLMMathChain.from_llm(llm, verbose=True)\n",
        "\n",
        "llm_math.run(\"What is 13 raised to the .3432 power?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "CjFl_NPsYNq3",
        "outputId": "49ae1122-a5c6-454d-edbf-63b71074da53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "What is 13 raised to the .3432 power?\u001b[32;1m\u001b[1;3m\n",
            "```text\n",
            "13 ** .3432\n",
            "```\n",
            "...numexpr.evaluate(\"13 ** .3432\")...\n",
            "\u001b[0m\n",
            "Answer: \u001b[33;1m\u001b[1;3m2.4116004626599237\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Answer: 2.4116004626599237'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDGo8pWYYNtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQGiKM5AYNvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zex4XeDeYNxo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
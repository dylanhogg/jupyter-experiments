{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab346e81-3c21-468d-b690-85735603fbca",
   "metadata": {},
   "source": [
    "# Pandas Best Practices - parallelised df.pipe() with caching (WIP)\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dylanhogg/jupyter-experiments/blob/master/notebooks/best-practices/pandas-pipe-parallel-with-caching.ipynb)  \n",
    "\n",
    "# References\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pipe.html  \n",
    "https://github.com/Delgan/loguru  \n",
    "https://github.com/nalepae/pandarallel  \n",
    "https://github.com/joblib/joblib  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa46b0cb-4f14-4e3d-82bc-3b815e0f4c0b",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e331912f-1cea-4404-94e7-44e1c6ca1fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install loguru -q  # Logging services; https://github.com/Delgan/loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122319a6-4d3b-4ca5-8282-cd83a5959c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandarallel -q  # Pandas parallel_apply(); https://github.com/nalepae/pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e91bf5-f67b-459f-83e8-5c541cec2eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install joblib -q  # Caching to disk; https://github.com/joblib/joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2d1fbf-5baf-4660-8e3c-6e64a49c26d4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d92f404-4293-4ba7-9874-9f00e43d67ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from functools import wraps\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b02c7-47cb-421d-80fd-7d09755e6499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "from pandarallel import pandarallel\n",
    "from joblib import Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97f78c1-d8e8-46a3-ad6c-01e7c4880430",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 100\n",
    "memory = Memory(\".joblib_cache\", verbose=0)\n",
    "nb_workers = psutil.cpu_count() * 2\n",
    "pandarallel.initialize(nb_workers=nb_workers, progress_bar=True)  # Add use_memory_fs=False to avoid /dev/shm space issue in Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4638eb-cd50-4988-bcd3-5084312ecdb8",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3236248-c56f-408e-921b-3c8baf98a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://s3.amazonaws.com/publicdata.infocruncher.com/awesomepython.org/goodreads_archive_v1_gzip.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd15a2e-d348-49b2-8d7c-8ed9a6b63f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(url, stream=True)\n",
    "length = int(resp.headers.get('content-length', 0))\n",
    "fname = url[url.rindex(\"/\")+1:]\n",
    "if Path(fname).exists():\n",
    "    logger.info(f\"Loading {fname} from disk\")\n",
    "    pass\n",
    "else:\n",
    "    with open(fname, \"wb\") as f:\n",
    "        with tqdm(total=length, unit='iB', unit_scale=True, desc=f\"Downloading {fname}\") as pbar:\n",
    "            for data in resp.iter_content(chunk_size=1048576):\n",
    "                pbar.update(len(data))\n",
    "                f.write(data)\n",
    "        assert pbar.n == length, \"Unexpected length\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f4d820-28b3-4bd0-9ff4-ff432cf7d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_parquet(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5401e-bda2-471f-a0f4-b1a590a287b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081eb122-d5ec-4f4f-bbd3-5ddb3178da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c577b44-7b9a-43cc-b3e1-b141ee091239",
   "metadata": {},
   "source": [
    "## Decorator helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d4f0b1-762c-46d0-9cfe-fd6d2877bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_pipeline_step(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs) -> pd.DataFrame:\n",
    "        input_shape = args[0].shape\n",
    "        logger.info(f\"{func.__name__}\")\n",
    "        tic = datetime.now()\n",
    "        df_result = func(*args, **kwargs)\n",
    "        output_shape = df_result.shape\n",
    "        logger.info(f\" ╰╴{func.__name__} took {datetime.now() - tic}s in: {input_shape} out: {output_shape} diff: ({output_shape[0] - input_shape[0]}, {output_shape[1] - input_shape[1]})\")\n",
    "        return df_result\n",
    "    return wrapper\n",
    "\n",
    "def log_columns(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        df_result = func(*args, **kwargs)\n",
    "        logger.info(f\"{func.__name__} cols ({len(df_result.columns)}): [{', '.join(list(df_result.columns))}]\")\n",
    "        return df_result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1415e6-3c70-47b6-ba96-ecccdf6994ac",
   "metadata": {},
   "source": [
    "## Generic pipe functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c248b7d-8021-46aa-b5c9-28785c056609",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_pipeline_step\n",
    "@log_columns\n",
    "def start_pipeline(dataf):\n",
    "    return dataf.copy()\n",
    "\n",
    "@log_columns\n",
    "def end_pipeline(dataf):\n",
    "    return dataf\n",
    "\n",
    "@log_pipeline_step\n",
    "def filter_rows(dataf: pd.DataFrame, column, min_value) -> pd.DataFrame:\n",
    "    return (dataf[dataf[column] >= min_value])\n",
    "\n",
    "@log_pipeline_step\n",
    "def sort_values(dataf: pd.DataFrame, col_names, ascending=False) -> pd.DataFrame:\n",
    "    return dataf.sort_values(by=col_names, ascending=ascending)\n",
    "\n",
    "@log_pipeline_step\n",
    "def move_col(dataf, col_name, index=0):\n",
    "    cols = dataf.columns.tolist()\n",
    "    cols.insert(index, cols.pop(cols.index(col_name)))\n",
    "    return dataf.loc[:, cols]\n",
    "\n",
    "@log_pipeline_step\n",
    "def calc_sum(dataf: pd.DataFrame, index_name= \"total\") -> pd.DataFrame:\n",
    "    def _numeric_sum(col):\n",
    "        return col.sum() if np.issubdtype(col.dtype, np.number) else None\n",
    "    dataf.loc[index_name] = dataf.apply(_numeric_sum, axis=0) # over columns\n",
    "    return dataf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed7ebe3-ba58-4159-a945-64d8eb335d96",
   "metadata": {},
   "source": [
    "## Custom pipe functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd60489-9cd7-4315-ac04-b50968706414",
   "metadata": {},
   "outputs": [],
   "source": [
    "@logger.catch  # Catch error information from threads\n",
    "@log_pipeline_step\n",
    "def expand_features(dataf: pd.DataFrame) -> pd.DataFrame:\n",
    "    @memory.cache  # Somewhat contrieved caching example here. Useful for expensive operations like API calls.\n",
    "    def _apply_cached(description, total_reviews, counts_of_review):\n",
    "        return {\n",
    "            \"_len_desc\": len(description) if description else 0, \n",
    "            \"_perc_reviews\": counts_of_review * 100 / total_reviews, \n",
    "        }\n",
    "        \n",
    "    def _apply(row):\n",
    "        return _apply_cached(row[\"Description\"], dataf[\"CountsOfReview\"].sum(), row[\"CountsOfReview\"])\n",
    "    \n",
    "    res = dataf.parallel_apply(_apply, axis=1, result_type='expand')  # .parallel_apply() via pandarallel\n",
    "    dataf[res.columns] = res\n",
    "    return dataf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a30324-a7be-4682-af52-46f1e2c70b60",
   "metadata": {},
   "source": [
    "## Pipeline example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f30817-4e5b-45b8-a423-49f5c0cc7927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df_raw\n",
    "      .pipe(start_pipeline)\n",
    "      .pipe(filter_rows, column=\"Rating\", min_value=4)\n",
    "      .pipe(expand_features)\n",
    "      .pipe(calc_sum)\n",
    "      .pipe(end_pipeline)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d91c89-8682-4390-ac09-d6ffdd43713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df52a790-2c61-4b5d-bc6f-5e69b38cedbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
